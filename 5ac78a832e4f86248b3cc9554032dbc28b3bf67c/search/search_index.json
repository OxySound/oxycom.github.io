{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to OxySound \u00b6 Introduction \u00b6 OxySound enables your apps to send and receive information using sound. We encode your data as an audio signal, which can be transmitted by any device with a speaker and received by any device with a microphone and OxySound SDK. It is designed to be robust over distances of several metres, and in noisy, everyday environments. As the transmission takes place entirely via audio signals, no internet connection or prior pairing is required, and any device within hearing range can receive the data. OxySound signals can be generated on-device from a dynamic data payload, or recorded as an audio file for later playback \u2013 like a sonic barcode. OxySound is designed for simplicity, eliminating connectivity headaches and simplifying everyday tasks like connecting to Wi-Fi networks, sharing contact details, and making peer-to-peer payments. Why ? \u00b6 You can find speakers in most places, and that makes this technology cheap and can be used in cases where communication is restricted.","title":"Introduction"},{"location":"#welcome-to-oxysound","text":"","title":"Welcome to OxySound"},{"location":"#introduction","text":"OxySound enables your apps to send and receive information using sound. We encode your data as an audio signal, which can be transmitted by any device with a speaker and received by any device with a microphone and OxySound SDK. It is designed to be robust over distances of several metres, and in noisy, everyday environments. As the transmission takes place entirely via audio signals, no internet connection or prior pairing is required, and any device within hearing range can receive the data. OxySound signals can be generated on-device from a dynamic data payload, or recorded as an audio file for later playback \u2013 like a sonic barcode. OxySound is designed for simplicity, eliminating connectivity headaches and simplifying everyday tasks like connecting to Wi-Fi networks, sharing contact details, and making peer-to-peer payments.","title":"Introduction"},{"location":"#why","text":"You can find speakers in most places, and that makes this technology cheap and can be used in cases where communication is restricted.","title":"Why ?"},{"location":"how-it-works/","text":"Start building \u00b6 \u00b6 Within each SDK, you will find a example application that demonstrates the SDK\u2019s basic functionality.","title":"Start building"},{"location":"how-it-works/#start-building","text":"","title":"Start building"},{"location":"how-it-works/#_1","text":"Within each SDK, you will find a example application that demonstrates the SDK\u2019s basic functionality.","title":""},{"location":"cases/1/","text":"Toolbox \u00b6 Introduction \u00b6 There are situations when data over sound is more viable than the standard solution over radio waves. The technology could be used where electro magnetic signals could interfere and are as such prohibited. It can be used as replacement for NFC and Bluetooth technology, a example is using sound data as a protocol for bus ticket validation. From a security perspective it can be used as authentication mechanism to login to websites or even physical devices, arguing that they are less likely hacked since physical presence of listening device or person is needed for sniffing data. Sound has obvious disadvantages. One is that it needs to deal with noise interference, which is everywhere. And in the open, the range is short: 10 to 20 feet. But the big advantage is easy to miss: the audio bursts are a one-to-many, multidirectional transmission. So OxySound can be used as a signal \u2013 say a trigger, or a wake up call \u2013 for millions of digital devices at once. It can be played at a stadium, for example. Ticketing \u00b6 Whether it's transportation services, large scale events, or simply controlling access to spaces, our technology has been proven as a reliable, frictionless and safe means to transmit and authenticate user information. With support for all major platforms and mobile devices, offline operation, and no prior pairing required, OxySound provides a truly universal way to authenticate your customers. Payments and Transactions \u00b6 When it comes to money, digital is king. From pop-up shops in Yemen, through street vendors in London, to simply transferring money to a friend, this digital revolution requires secure, low-cost, and highly accessible technology to ensure making a payment is as simple as pressing a button. Provisioning \u00b6 In a world where computers have permeated every corner of our surroundings, the need for devices to share information with minimal human input is more apparent than ever. Many devices have the hardware capacity to communicate using audio, particularly those in the home such as smart speakers and voice assistants. OxySound allows for these devices to be seamlessly connected to your local wifi network, without having to access a clunky web portal to enter credentials. Broadcast \u00b6 Fancy sharing a voucher with all viewers of a TV advertisement or radio programme? How about sending a discount code to all audience members at a concert or festival? One of the many beauties of our technology is the ability to broadcast data to many devices at once, even in extremely noisy environments and large spaces. No Limits \u00b6 The technology use cases is only limited by imgination, but we can help design your use case.","title":"Use Cases"},{"location":"cases/1/#toolbox","text":"","title":"Toolbox"},{"location":"cases/1/#introduction","text":"There are situations when data over sound is more viable than the standard solution over radio waves. The technology could be used where electro magnetic signals could interfere and are as such prohibited. It can be used as replacement for NFC and Bluetooth technology, a example is using sound data as a protocol for bus ticket validation. From a security perspective it can be used as authentication mechanism to login to websites or even physical devices, arguing that they are less likely hacked since physical presence of listening device or person is needed for sniffing data. Sound has obvious disadvantages. One is that it needs to deal with noise interference, which is everywhere. And in the open, the range is short: 10 to 20 feet. But the big advantage is easy to miss: the audio bursts are a one-to-many, multidirectional transmission. So OxySound can be used as a signal \u2013 say a trigger, or a wake up call \u2013 for millions of digital devices at once. It can be played at a stadium, for example.","title":"Introduction"},{"location":"cases/1/#ticketing","text":"Whether it's transportation services, large scale events, or simply controlling access to spaces, our technology has been proven as a reliable, frictionless and safe means to transmit and authenticate user information. With support for all major platforms and mobile devices, offline operation, and no prior pairing required, OxySound provides a truly universal way to authenticate your customers.","title":"Ticketing"},{"location":"cases/1/#payments-and-transactions","text":"When it comes to money, digital is king. From pop-up shops in Yemen, through street vendors in London, to simply transferring money to a friend, this digital revolution requires secure, low-cost, and highly accessible technology to ensure making a payment is as simple as pressing a button.","title":"Payments and Transactions"},{"location":"cases/1/#provisioning","text":"In a world where computers have permeated every corner of our surroundings, the need for devices to share information with minimal human input is more apparent than ever. Many devices have the hardware capacity to communicate using audio, particularly those in the home such as smart speakers and voice assistants. OxySound allows for these devices to be seamlessly connected to your local wifi network, without having to access a clunky web portal to enter credentials.","title":"Provisioning"},{"location":"cases/1/#broadcast","text":"Fancy sharing a voucher with all viewers of a TV advertisement or radio programme? How about sending a discount code to all audience members at a concert or festival? One of the many beauties of our technology is the ability to broadcast data to many devices at once, even in extremely noisy environments and large spaces.","title":"Broadcast"},{"location":"cases/1/#no-limits","text":"The technology use cases is only limited by imgination, but we can help design your use case.","title":"No Limits"},{"location":"components/audible/","text":"Protocols \u00b6 OxySound SDKs can be configured to use different communication protocols, which determine various properties of the transmission. All \u00b6 OxySound will listen simultaneously for multiple protocols, for example sending an audible then an Near-ultrasonic signal will both be processed without restarting the SDK unless a specific mode is selected or custom frequencies are in use. The default is All Audible \u00b6 Audible frequencies are recommended for channels which have a limited audio sample rate -- VoIP connections, lossy codecs, or lower-spec embedded devices. Specific protocols are available for each of these scenarios. Near-ultrasonic \u00b6 Near-ultrasonic frequencies should be used when noise disturbance is not wanted. Frequencies between 17kHz and 21kHz are supported by virtually all mobiles and computers, but are generally inaudible to the human ear. How it will sound \u00b6 For scenarios in which a more tuneful tone is desirable -- for example, in children's toys -- the transmission can be tailored to sound more tuneful. By using ultrasonic data layered over another piece of sound, devices can even appear to communicate using arbitrary audio. Compression \u00b6 For scenarios where embeding into media is desirable -- for example, in Youtube -- the transmission can be tailored to send second screen experience. By using data layered over another is possible to send more than data transmission for example the seconds of the video and a custom message. Custom Frequencies \u00b6 For scenarios where control is a must you can choose a start and Frequence. Additional protocols \u00b6 Available on request, including: pstn: for transmission over phone lines and VoIP long-range: for large venues, industrial and stadium transmissions nfc: for high-speed, short-range transmission","title":"All"},{"location":"components/audible/#protocols","text":"OxySound SDKs can be configured to use different communication protocols, which determine various properties of the transmission.","title":"Protocols"},{"location":"components/audible/#all","text":"OxySound will listen simultaneously for multiple protocols, for example sending an audible then an Near-ultrasonic signal will both be processed without restarting the SDK unless a specific mode is selected or custom frequencies are in use. The default is All","title":"All"},{"location":"components/audible/#audible","text":"Audible frequencies are recommended for channels which have a limited audio sample rate -- VoIP connections, lossy codecs, or lower-spec embedded devices. Specific protocols are available for each of these scenarios.","title":"Audible"},{"location":"components/audible/#near-ultrasonic","text":"Near-ultrasonic frequencies should be used when noise disturbance is not wanted. Frequencies between 17kHz and 21kHz are supported by virtually all mobiles and computers, but are generally inaudible to the human ear.","title":"Near-ultrasonic"},{"location":"components/audible/#how-it-will-sound","text":"For scenarios in which a more tuneful tone is desirable -- for example, in children's toys -- the transmission can be tailored to sound more tuneful. By using ultrasonic data layered over another piece of sound, devices can even appear to communicate using arbitrary audio.","title":"How it will sound"},{"location":"components/audible/#compression","text":"For scenarios where embeding into media is desirable -- for example, in Youtube -- the transmission can be tailored to send second screen experience. By using data layered over another is possible to send more than data transmission for example the seconds of the video and a custom message.","title":"Compression"},{"location":"components/audible/#custom-frequencies","text":"For scenarios where control is a must you can choose a start and Frequence.","title":"Custom Frequencies"},{"location":"components/audible/#additional-protocols","text":"Available on request, including: pstn: for transmission over phone lines and VoIP long-range: for large venues, industrial and stadium transmissions nfc: for high-speed, short-range transmission","title":"Additional protocols"},{"location":"components/b/","text":"","title":"Bytes"},{"location":"components/c/","text":"Getting Started - C++ \u00b6 Create Object and Destory \u00b6 void *OXY_Create(); void OXY_Destroy(void *oxyingObject); Configure Profile \u00b6 Configure function, call this function to configure parameters of the Oxy Core Library mode Parameters: mode (2 for audible, 3 for non-audible) samplingRate: sampling rate in Hz nChannels: number of channels of the input audio Object: OXY object instance, created in OXY_Create() Returns: 0=ok, <0=fail Configure(int mode, float samplingRate, int32_t bufferSize, void *oxyingObject); Custom Audio Output \u00b6 Create custom audio, call this function to set a personalized audio that will be played simultaneously during oxying playback on top of non-audible, audible or compression modes Parameters: samplesSize: number of samples in samples buffer (maximum size is 2 seconds= 44100*2) samples: array with samples (44Khz, 16bits, mono) oxyingObject: OXY object instance, created in OXY_Create() Returns: 0=ok, <0=fail SetAudioSignature(int32_t samplesSize, const float *samplesBuffer, void *oxyingObject); Encode Data \u00b6 Parameters: stringToEncode: string containing the characters to encode size: number of characters in string characters to encode type: 0 for encoding only tones, 1 for encoding tones + R2D2 sounds, 2 for encoding melody melodyString: string containing characters to synthesize melody over the tones (null if type parameter is 0 or 1) melodySize: size of melody in number of notes (0 if type parameter is 0 or 1) oxyingObject: OXY object instance, created in OXY_Create() Returns: number of samples in encoded audio buffer EncodeDataToAudioBuffer(const char *stringToEncode, int32_t size, int32_t type, const char *melodyString, int32_t melodySize, void *oxyingObject); Encoded Audio Buffer \u00b6 GetEncodedAudioBuffer function Parameters: audioBuffer: float array of bufferSize size to fill with encoded audio data oxyingObject: OXY object instance, created in OXY_Create() GetEncodedAudioBuffer(float *audioBuffer, void *oxyingObject); Read Audio Buffer \u00b6 CreateAudioBufferFromData function, resets the read index on the internal buffer that has the encoded string Parameters: oxyingObject: OXY object instance, created in OXY_Create() Returns: 0=ok, <0=fail ResetEncodedAudioBuffer(void *oxyingObject); Decode Audio \u00b6 DecodeAudioBuffer function, receives an audiobuffer of specified size and outputs if encoded data is found Parameters: audioBuffer: float array of bufferSize size with audio data to be decoded size: size of audioBuffer oxyingObject: OXY object instance, created in OXY_Create() Returns: -1 if no decoded data is found, -2 if start token is found, -3 if complete word has been decoded, positive number if character is decoded (number is the token idx) DecodeAudioBuffer(float *audioBuffer, int size, void *oxyingObject); Get Decoded Data \u00b6 GetDecodedData function, retrieves the last decoded data found Parameters: stringDecoded: string containing decoded characters oxyingObject: OXY object instance, created in OXY_Create() Returns: 0 if no decoded data is available, >0 if data is available and it's ok, <0 if data is available but it's wrong, for the last two cases the return value magnitude contains number of characters in string decoded GetDecodedData(char *stringDecoded, void *oxyingObject); Get Confidence \u00b6 Confidence function, outputs Reception Quality Measure to give confidence about the received audio. A Reception Quality value of 1.0 will mean that the reception conditions are ideal, a lower value will mean that listener is in a noisy environment, the listener should be closer to the transmitter, etc. Parameters: oxyingObject: OXY object instance, created in OXY_Create() Returns: confidence value from 0.0 o 1.0 GetConfidence(void *oxyingObject); //Get global confidence (combination of the other confidence values) GetConfidenceError(void *oxyingObject); //Get confidence due to tokens corrected by correction algorithm GetConfidenceNoise(void *oxyingObject); //Get confidence due to signal to noise ratio in received audio Get Received \u00b6 Get average received volume of last audio transmission in DB GetReceivedOxysVolume(void *oxyingObject); Get Decode Mode \u00b6 GetDecodedMode function, outputs an integer representation of the decoded mode found from all available decoding modes, it only makes sense when decoder is configured with the ALL mode, for other modes decoded mode will be always the same as the decoding mode. Parameters: Returns: decoded mode found ( AUDIBLE = 0, NONAUDIBLE = 1, COMPRESSION = 2 ) GetDecodedMode(void *oxyingObject); Base Frequency \u00b6 Function to set custom base freq SetCustomBaseFreq(float baseFreq, int oxysSeparation, void *oxyingObject); Frequency Range \u00b6 Functions to get decoding frequency range (begin range frequency and end range frequency) GetDecodingBeginFreq(void *oxyingObject); GetDecodingEndFreq(void *oxyingObject);","title":"C/C++"},{"location":"components/c/#getting-started-c","text":"","title":"Getting Started - C++"},{"location":"components/c/#create-object-and-destory","text":"void *OXY_Create(); void OXY_Destroy(void *oxyingObject);","title":"Create Object and Destory"},{"location":"components/c/#configure-profile","text":"Configure function, call this function to configure parameters of the Oxy Core Library mode Parameters: mode (2 for audible, 3 for non-audible) samplingRate: sampling rate in Hz nChannels: number of channels of the input audio Object: OXY object instance, created in OXY_Create() Returns: 0=ok, <0=fail Configure(int mode, float samplingRate, int32_t bufferSize, void *oxyingObject);","title":"Configure Profile"},{"location":"components/c/#custom-audio-output","text":"Create custom audio, call this function to set a personalized audio that will be played simultaneously during oxying playback on top of non-audible, audible or compression modes Parameters: samplesSize: number of samples in samples buffer (maximum size is 2 seconds= 44100*2) samples: array with samples (44Khz, 16bits, mono) oxyingObject: OXY object instance, created in OXY_Create() Returns: 0=ok, <0=fail SetAudioSignature(int32_t samplesSize, const float *samplesBuffer, void *oxyingObject);","title":"Custom Audio Output"},{"location":"components/c/#encode-data","text":"Parameters: stringToEncode: string containing the characters to encode size: number of characters in string characters to encode type: 0 for encoding only tones, 1 for encoding tones + R2D2 sounds, 2 for encoding melody melodyString: string containing characters to synthesize melody over the tones (null if type parameter is 0 or 1) melodySize: size of melody in number of notes (0 if type parameter is 0 or 1) oxyingObject: OXY object instance, created in OXY_Create() Returns: number of samples in encoded audio buffer EncodeDataToAudioBuffer(const char *stringToEncode, int32_t size, int32_t type, const char *melodyString, int32_t melodySize, void *oxyingObject);","title":"Encode Data"},{"location":"components/c/#encoded-audio-buffer","text":"GetEncodedAudioBuffer function Parameters: audioBuffer: float array of bufferSize size to fill with encoded audio data oxyingObject: OXY object instance, created in OXY_Create() GetEncodedAudioBuffer(float *audioBuffer, void *oxyingObject);","title":"Encoded Audio Buffer"},{"location":"components/c/#read-audio-buffer","text":"CreateAudioBufferFromData function, resets the read index on the internal buffer that has the encoded string Parameters: oxyingObject: OXY object instance, created in OXY_Create() Returns: 0=ok, <0=fail ResetEncodedAudioBuffer(void *oxyingObject);","title":"Read Audio Buffer"},{"location":"components/c/#decode-audio","text":"DecodeAudioBuffer function, receives an audiobuffer of specified size and outputs if encoded data is found Parameters: audioBuffer: float array of bufferSize size with audio data to be decoded size: size of audioBuffer oxyingObject: OXY object instance, created in OXY_Create() Returns: -1 if no decoded data is found, -2 if start token is found, -3 if complete word has been decoded, positive number if character is decoded (number is the token idx) DecodeAudioBuffer(float *audioBuffer, int size, void *oxyingObject);","title":"Decode Audio"},{"location":"components/c/#get-decoded-data","text":"GetDecodedData function, retrieves the last decoded data found Parameters: stringDecoded: string containing decoded characters oxyingObject: OXY object instance, created in OXY_Create() Returns: 0 if no decoded data is available, >0 if data is available and it's ok, <0 if data is available but it's wrong, for the last two cases the return value magnitude contains number of characters in string decoded GetDecodedData(char *stringDecoded, void *oxyingObject);","title":"Get Decoded Data"},{"location":"components/c/#get-confidence","text":"Confidence function, outputs Reception Quality Measure to give confidence about the received audio. A Reception Quality value of 1.0 will mean that the reception conditions are ideal, a lower value will mean that listener is in a noisy environment, the listener should be closer to the transmitter, etc. Parameters: oxyingObject: OXY object instance, created in OXY_Create() Returns: confidence value from 0.0 o 1.0 GetConfidence(void *oxyingObject); //Get global confidence (combination of the other confidence values) GetConfidenceError(void *oxyingObject); //Get confidence due to tokens corrected by correction algorithm GetConfidenceNoise(void *oxyingObject); //Get confidence due to signal to noise ratio in received audio","title":"Get Confidence"},{"location":"components/c/#get-received","text":"Get average received volume of last audio transmission in DB GetReceivedOxysVolume(void *oxyingObject);","title":"Get Received"},{"location":"components/c/#get-decode-mode","text":"GetDecodedMode function, outputs an integer representation of the decoded mode found from all available decoding modes, it only makes sense when decoder is configured with the ALL mode, for other modes decoded mode will be always the same as the decoding mode. Parameters: Returns: decoded mode found ( AUDIBLE = 0, NONAUDIBLE = 1, COMPRESSION = 2 ) GetDecodedMode(void *oxyingObject);","title":"Get Decode Mode"},{"location":"components/c/#base-frequency","text":"Function to set custom base freq SetCustomBaseFreq(float baseFreq, int oxysSeparation, void *oxyingObject);","title":"Base Frequency"},{"location":"components/c/#frequency-range","text":"Functions to get decoding frequency range (begin range frequency and end range frequency) GetDecodingBeginFreq(void *oxyingObject); GetDecodingEndFreq(void *oxyingObject);","title":"Frequency Range"},{"location":"components/custom/","text":"Custom sound \u00b6 How it will sound \u00b6 For scenarios in which a more tuneful tone is desirable -- for example, in children's toys -- the transmission can be tailored to sound more tuneful. By using ultrasonic data layered over another piece of sound, devices can even appear to communicate using arbitrary audio","title":"Custom sound"},{"location":"components/custom/#custom-sound","text":"","title":"Custom sound"},{"location":"components/custom/#how-it-will-sound","text":"For scenarios in which a more tuneful tone is desirable -- for example, in children's toys -- the transmission can be tailored to sound more tuneful. By using ultrasonic data layered over another piece of sound, devices can even appear to communicate using arbitrary audio","title":"How it will sound"},{"location":"components/k/","text":"Payload string \u00b6 Strings \u00b6 Commonly, a developer will want to send a short unicode string \u2014 typically an identifier of some sort, which could be related to an asset, an address, or even just a short message. The example below shows how to Swift \u00b6 oxyManager!.play(\"829450000\", withType: 0) Objective-C \u00b6 [_oxyManager play:\"123450000\" withType:0]; Kotlin \u00b6 oxyManager!.play(\"829450000\", withType: 0) C ++ \u00b6 EncodeDataToAudioBuffer(\"123450000\", 9, 0, null, 0, oxyingObject);","title":"String"},{"location":"components/k/#payload-string","text":"","title":"Payload string"},{"location":"components/k/#strings","text":"Commonly, a developer will want to send a short unicode string \u2014 typically an identifier of some sort, which could be related to an asset, an address, or even just a short message. The example below shows how to","title":"Strings"},{"location":"components/k/#swift","text":"oxyManager!.play(\"829450000\", withType: 0)","title":"Swift"},{"location":"components/k/#objective-c","text":"[_oxyManager play:\"123450000\" withType:0];","title":"Objective-C"},{"location":"components/k/#kotlin","text":"oxyManager!.play(\"829450000\", withType: 0)","title":"Kotlin"},{"location":"components/k/#c","text":"EncodeDataToAudioBuffer(\"123450000\", 9, 0, null, 0, oxyingObject);","title":"C ++"},{"location":"components/sdk-android/","text":"Getting Started - Android \u00b6 AAR \u00b6 Copy the oxy.aar file to your app/libs directory. Add the following to the dependencies block of your Module build.gradle Gradle script. To instruct Gradle where to find the local .aar file, add flatDir section to the repositories block. (You\u2019ll need to add a repositories block if one does not already exist). repositories { flatDir { dirs 'libs' } } Permissions \u00b6 Declare your app's audio permissions Add the following to your AndroidManifest.xml, inside the bottom of the element. <uses-permission android:name=\"android.permission.RECORD_AUDIO\" /> SDK requires at minimum of Android 5.0.x which is Android API level 26. Import the SDK \u00b6 import com.oxy.AndroidOxyCore.OxyCore import com.oxy.AndroidOxyCore.OxyCoreEvent Instantiate the SDK private lateinit var SDKOxyCore: OxyCore class MainActivity : AppCompatActivity(), OxyCoreEvent { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) //Provide Context for Callback SDKOxyCore = OxyCore(this) } } //Callback override fun IdWith(Id: String) { } Request microphone permissions and start the engine override fun onResume() { super.onResume() SDKOxyCore.Listen() } States \u00b6 Pause \u00b6 override fun onPause() { super.onPause() SDKOxyCore.Stop() } Destory the instance \u00b6 Stop and close the SDK when activity is destroyed. In order to make sure the SDK will be closed, we need to call the close method to empty the memory and to delete the instance when the activity is destroyed. override fun onDestroy() { super.onDestroy() SDKOxyCore.Stop() } Gradle \u00b6 To access the SDK add the repositories to bundle.gradle (Module: App) and set the credentials to gradle.properties (Project). #Your demo credits UsrSDK=Demo TokenSDK=jshewhuijndu3hjahdswjjweSAuheujkk2ijknbhih3jkwuheijN== Bundle.gradle (Module.gradle) apply plugin: 'com.android.application' apply plugin: 'kotlin-android' apply plugin: 'kotlin-android-extensions' android { compileSdkVersion 29 buildToolsVersion \"29.0.3\" defaultConfig { applicationId \"com.example.oxysound\" minSdkVersion 26 targetSdkVersion 29 versionCode 1 versionName \"1.0\" testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\" } buildTypes { release { minifyEnabled false proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro' } } } repositories { maven { credentials { username UsrSDK password TokenSDK } url \"https://cidwp-249609.appspot.com/\" } } dependencies { implementation fileTree(include: ['*.jar'], dir: 'libs') implementation \"org.jetbrains.kotlin:kotlin-stdlib-jdk7:$kotlin_version\" implementation 'androidx.appcompat:appcompat:1.1.0' implementation 'androidx.core:core-ktx:1.3.0' implementation 'androidx.constraintlayout:constraintlayout:1.1.3' testImplementation 'junit:junit:4.12' androidTestImplementation 'androidx.test.ext:junit:1.1.1' androidTestImplementation 'androidx.test.espresso:espresso-core:3.2.0' implementation 'com.oxysound:sdk:1.0.15.22' } You are now ready to start using OxySound in your own application.","title":"Android"},{"location":"components/sdk-android/#getting-started-android","text":"","title":"Getting Started - Android"},{"location":"components/sdk-android/#aar","text":"Copy the oxy.aar file to your app/libs directory. Add the following to the dependencies block of your Module build.gradle Gradle script. To instruct Gradle where to find the local .aar file, add flatDir section to the repositories block. (You\u2019ll need to add a repositories block if one does not already exist). repositories { flatDir { dirs 'libs' } }","title":"AAR"},{"location":"components/sdk-android/#permissions","text":"Declare your app's audio permissions Add the following to your AndroidManifest.xml, inside the bottom of the element. <uses-permission android:name=\"android.permission.RECORD_AUDIO\" /> SDK requires at minimum of Android 5.0.x which is Android API level 26.","title":"Permissions"},{"location":"components/sdk-android/#import-the-sdk","text":"import com.oxy.AndroidOxyCore.OxyCore import com.oxy.AndroidOxyCore.OxyCoreEvent Instantiate the SDK private lateinit var SDKOxyCore: OxyCore class MainActivity : AppCompatActivity(), OxyCoreEvent { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) //Provide Context for Callback SDKOxyCore = OxyCore(this) } } //Callback override fun IdWith(Id: String) { } Request microphone permissions and start the engine override fun onResume() { super.onResume() SDKOxyCore.Listen() }","title":"Import the SDK"},{"location":"components/sdk-android/#states","text":"","title":"States"},{"location":"components/sdk-android/#pause","text":"override fun onPause() { super.onPause() SDKOxyCore.Stop() }","title":"Pause"},{"location":"components/sdk-android/#destory-the-instance","text":"Stop and close the SDK when activity is destroyed. In order to make sure the SDK will be closed, we need to call the close method to empty the memory and to delete the instance when the activity is destroyed. override fun onDestroy() { super.onDestroy() SDKOxyCore.Stop() }","title":"Destory the instance"},{"location":"components/sdk-android/#gradle","text":"To access the SDK add the repositories to bundle.gradle (Module: App) and set the credentials to gradle.properties (Project). #Your demo credits UsrSDK=Demo TokenSDK=jshewhuijndu3hjahdswjjweSAuheujkk2ijknbhih3jkwuheijN== Bundle.gradle (Module.gradle) apply plugin: 'com.android.application' apply plugin: 'kotlin-android' apply plugin: 'kotlin-android-extensions' android { compileSdkVersion 29 buildToolsVersion \"29.0.3\" defaultConfig { applicationId \"com.example.oxysound\" minSdkVersion 26 targetSdkVersion 29 versionCode 1 versionName \"1.0\" testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\" } buildTypes { release { minifyEnabled false proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro' } } } repositories { maven { credentials { username UsrSDK password TokenSDK } url \"https://cidwp-249609.appspot.com/\" } } dependencies { implementation fileTree(include: ['*.jar'], dir: 'libs') implementation \"org.jetbrains.kotlin:kotlin-stdlib-jdk7:$kotlin_version\" implementation 'androidx.appcompat:appcompat:1.1.0' implementation 'androidx.core:core-ktx:1.3.0' implementation 'androidx.constraintlayout:constraintlayout:1.1.3' testImplementation 'junit:junit:4.12' androidTestImplementation 'androidx.test.ext:junit:1.1.1' androidTestImplementation 'androidx.test.espresso:espresso-core:3.2.0' implementation 'com.oxysound:sdk:1.0.15.22' } You are now ready to start using OxySound in your own application.","title":"Gradle"},{"location":"components/sdk-arm/","text":"Getting Started - Arduino \u00b6 The OxySound SDK for Arm Cortex processors allows you to send and receive data-over-sound from within your embedded C/C++ application. It harnesses the powerful in-built FPU and optimised CMSIS-DSP library to enable on-chip encoding and decoding of OxySound signals. Requirements \u00b6 To build an embedded system that uses the OxySound Arm SDK, you will need the following components. Arm Cortex-M4 or Arm Cortex-M7 CPU Audio ADC/DAC capable of at least 16kHz operation For input, a microphone. We recommend a MEMS mic, ideally with a flat frequency response. For output, a loudspeaker. Arduino Studio \u00b6 Check back soon for example","title":"Ardunio"},{"location":"components/sdk-arm/#getting-started-arduino","text":"The OxySound SDK for Arm Cortex processors allows you to send and receive data-over-sound from within your embedded C/C++ application. It harnesses the powerful in-built FPU and optimised CMSIS-DSP library to enable on-chip encoding and decoding of OxySound signals.","title":"Getting Started - Arduino"},{"location":"components/sdk-arm/#requirements","text":"To build an embedded system that uses the OxySound Arm SDK, you will need the following components. Arm Cortex-M4 or Arm Cortex-M7 CPU Audio ADC/DAC capable of at least 16kHz operation For input, a microphone. We recommend a MEMS mic, ideally with a flat frequency response. For output, a loudspeaker.","title":"Requirements"},{"location":"components/sdk-arm/#arduino-studio","text":"Check back soon for example","title":"Arduino Studio"},{"location":"components/sdk-iphone/","text":"Getting Started - iOS \u00b6 Framework \u00b6 Import the SDK into your project by dragging and dropping the .framework file into your Xcode project. Set \u2018Copy items if needed\u2019 if the framework is not already within your project folder. Add the framework to Linked Frameworks and Libraries Go to the Project Settings, under the General tab, and add Oxy.framework to \"Linked Frameworks and Libraries\". Add a microphone privacy statement \u00b6 This text is displayed when your app first launches and asks the user for microphone permission, and should describe why you are requesting access to the microphone. The request message should be short and specific and include an example of how the microphone data will be used, for example We need access to the microphone to receive messages from nearby devices using sound. Under the Info tab in the Project Settings, add a Custom iOS Target Property called \"Privacy - Microphone Usage Description\". Disable Bitcode for the SDK \u00b6 Under the Build Settings tab in the Project Settings, under Build Options, set \"Enable Bitcode\" to No. Add a bridging header to the framework [Swift Only] Add a new Objective-C file to your Swift project. Xcode will prompt if you want to configure your project with a bridging header. Press yes. Once the bridging header is added to your project, you can delete the Objective-C file if you want to. Inside the bridging header, import the Oxy framework. This will make it available throughout your project\u2019s Swift files. Now for the code... \u00b6 Include the SDK and its associated configuration header: import Oxy And instantiate the SDK (A key will required in the future) let OxyManager = Oxy.instance() oxyManager?.delegate=self To receive this data on a second device, simply implement the delegate. class ViewController: UIViewController, oxyDelegate { } func oxyId(with oxy_id: String!) { DispatchQueue.main.async { //Do some magic } } Start oxyManager!.listen() You are now ready to start using OxySound in your own application. Advanced usage \u00b6 Preselected frequencies and tone seperations func custom(freq: Float, sep: Int) { oxyManager!.setCustomBaseFreq(freq, withSeparation: Int32(sep)) oxyManager!.configure(oxyManager, with: CUSTOM) self.oxyManager!.listen() } To limit user interaction with broadcasts a set distance can be set and when below this distance the SDK will respond. if(self.oxyManager!.distanceVol() < self.amax ) { } Send audio from the SDK. Type options are 0/1 or 2 this relates to should the broadcast be mixed with an external media file or not Broadcast tone with SDK configuration oxyManager!.play(\"829450000\", withType: 0) Audible R2D2 tone oxyManager!.play(\"829450000\", withType: 1) External media let soundURLg = Bundle.main.url(forResource: \"storm\", withExtension: \"wav\") ... oxyManager!.play(\"929450000\", withType: 2) CocoaPods \u00b6 Add the following to your pod or gitclone to download the framework # Demo creds pod 'OxySDK', :git => 'https://35c1e102b7ac4fc033394281fca3234a57782d1c@github.com/OxySound/OxySDK.git'","title":"iPhone"},{"location":"components/sdk-iphone/#getting-started-ios","text":"","title":"Getting Started - iOS"},{"location":"components/sdk-iphone/#framework","text":"Import the SDK into your project by dragging and dropping the .framework file into your Xcode project. Set \u2018Copy items if needed\u2019 if the framework is not already within your project folder. Add the framework to Linked Frameworks and Libraries Go to the Project Settings, under the General tab, and add Oxy.framework to \"Linked Frameworks and Libraries\".","title":"Framework"},{"location":"components/sdk-iphone/#add-a-microphone-privacy-statement","text":"This text is displayed when your app first launches and asks the user for microphone permission, and should describe why you are requesting access to the microphone. The request message should be short and specific and include an example of how the microphone data will be used, for example We need access to the microphone to receive messages from nearby devices using sound. Under the Info tab in the Project Settings, add a Custom iOS Target Property called \"Privacy - Microphone Usage Description\".","title":"Add a microphone privacy statement"},{"location":"components/sdk-iphone/#disable-bitcode-for-the-sdk","text":"Under the Build Settings tab in the Project Settings, under Build Options, set \"Enable Bitcode\" to No. Add a bridging header to the framework [Swift Only] Add a new Objective-C file to your Swift project. Xcode will prompt if you want to configure your project with a bridging header. Press yes. Once the bridging header is added to your project, you can delete the Objective-C file if you want to. Inside the bridging header, import the Oxy framework. This will make it available throughout your project\u2019s Swift files.","title":"Disable Bitcode for the SDK"},{"location":"components/sdk-iphone/#now-for-the-code","text":"Include the SDK and its associated configuration header: import Oxy And instantiate the SDK (A key will required in the future) let OxyManager = Oxy.instance() oxyManager?.delegate=self To receive this data on a second device, simply implement the delegate. class ViewController: UIViewController, oxyDelegate { } func oxyId(with oxy_id: String!) { DispatchQueue.main.async { //Do some magic } } Start oxyManager!.listen() You are now ready to start using OxySound in your own application.","title":"Now for the code..."},{"location":"components/sdk-iphone/#advanced-usage","text":"Preselected frequencies and tone seperations func custom(freq: Float, sep: Int) { oxyManager!.setCustomBaseFreq(freq, withSeparation: Int32(sep)) oxyManager!.configure(oxyManager, with: CUSTOM) self.oxyManager!.listen() } To limit user interaction with broadcasts a set distance can be set and when below this distance the SDK will respond. if(self.oxyManager!.distanceVol() < self.amax ) { } Send audio from the SDK. Type options are 0/1 or 2 this relates to should the broadcast be mixed with an external media file or not Broadcast tone with SDK configuration oxyManager!.play(\"829450000\", withType: 0) Audible R2D2 tone oxyManager!.play(\"829450000\", withType: 1) External media let soundURLg = Bundle.main.url(forResource: \"storm\", withExtension: \"wav\") ... oxyManager!.play(\"929450000\", withType: 2)","title":"Advanced usage"},{"location":"components/sdk-iphone/#cocoapods","text":"Add the following to your pod or gitclone to download the framework # Demo creds pod 'OxySDK', :git => 'https://35c1e102b7ac4fc033394281fca3234a57782d1c@github.com/OxySound/OxySDK.git'","title":"CocoaPods"},{"location":"components/sdk-linux/","text":"Getting Started - PI/Linux \u00b6 The OxySound SDK for Arm Cortex processors allows you to send and receive data-over-sound from within your embedded C/C++ application for encoding and decoding of OxySound signals. Requirements \u00b6 To build an embedded system that uses the OxySound Pi SDK, you will need the following components. Arm Cortex-A72 architecture variant CPU For input, a microphone. We recommend the ReSpeaker 2 mics Hat. For output, a loudspeaker.","title":"Pi/Linux"},{"location":"components/sdk-linux/#getting-started-pilinux","text":"The OxySound SDK for Arm Cortex processors allows you to send and receive data-over-sound from within your embedded C/C++ application for encoding and decoding of OxySound signals.","title":"Getting Started - PI/Linux"},{"location":"components/sdk-linux/#requirements","text":"To build an embedded system that uses the OxySound Pi SDK, you will need the following components. Arm Cortex-A72 architecture variant CPU For input, a microphone. We recommend the ReSpeaker 2 mics Hat. For output, a loudspeaker.","title":"Requirements"},{"location":"components/sdk-mac/","text":"Getting Started - MacOS \u00b6 Framework \u00b6 Import the SDK into your project by dragging and dropping the .framework file into your Xcode project. Set \u2018Copy items if needed\u2019 if the framework is not already within your project folder. Add the framework to Linked Frameworks and Libraries Go to the Project Settings, under the General tab, and add Oxy.framework to \"Linked Frameworks and Libraries\". Add a microphone privacy statement \u00b6 This text is displayed when your app first launches and asks the user for microphone permission, and should describe why you are requesting access to the microphone. The request message should be short and specific and include an example of how the microphone data will be used, for example We need access to the microphone to receive messages from nearby devices using sound. Under the Info tab in the Project Settings, add a Custom iOS Target Property called \"Privacy - Microphone Usage Description\". Disable Bitcode for the SDK \u00b6 Under the Build Settings tab in the Project Settings, under Build Options, set \"Enable Bitcode\" to No. Add a bridging header to the framework [Swift Only] Add a new Objective-C file to your Swift project. Xcode will prompt if you want to configure your project with a bridging header. Press yes. Once the bridging header is added to your project, you can delete the Objective-C file if you want to. Inside the bridging header, import the Oxy framework. This will make it available throughout your project\u2019s Swift files. Now for the code... \u00b6 Include the SDK and its associated configuration header: import Oxy And instantiate the SDK (A key will required in the future) let OxyManager = Oxy.instance() oxyManager?.delegate=self \u00b6 To receive this data on a second device, simply implement the delegate. class ViewController: UIViewController, oxyDelegate { } func oxyId(with oxy_id: String!) { DispatchQueue.main.async { //Do some magic } } Start oxyManager!.listen() You are now ready to start using OxySound in your own application.","title":"MacOS"},{"location":"components/sdk-mac/#getting-started-macos","text":"","title":"Getting Started - MacOS"},{"location":"components/sdk-mac/#framework","text":"Import the SDK into your project by dragging and dropping the .framework file into your Xcode project. Set \u2018Copy items if needed\u2019 if the framework is not already within your project folder. Add the framework to Linked Frameworks and Libraries Go to the Project Settings, under the General tab, and add Oxy.framework to \"Linked Frameworks and Libraries\".","title":"Framework"},{"location":"components/sdk-mac/#add-a-microphone-privacy-statement","text":"This text is displayed when your app first launches and asks the user for microphone permission, and should describe why you are requesting access to the microphone. The request message should be short and specific and include an example of how the microphone data will be used, for example We need access to the microphone to receive messages from nearby devices using sound. Under the Info tab in the Project Settings, add a Custom iOS Target Property called \"Privacy - Microphone Usage Description\".","title":"Add a microphone privacy statement"},{"location":"components/sdk-mac/#disable-bitcode-for-the-sdk","text":"Under the Build Settings tab in the Project Settings, under Build Options, set \"Enable Bitcode\" to No. Add a bridging header to the framework [Swift Only] Add a new Objective-C file to your Swift project. Xcode will prompt if you want to configure your project with a bridging header. Press yes. Once the bridging header is added to your project, you can delete the Objective-C file if you want to. Inside the bridging header, import the Oxy framework. This will make it available throughout your project\u2019s Swift files.","title":"Disable Bitcode for the SDK"},{"location":"components/sdk-mac/#now-for-the-code","text":"Include the SDK and its associated configuration header: import Oxy And instantiate the SDK (A key will required in the future) let OxyManager = Oxy.instance() oxyManager?.delegate=self","title":"Now for the code..."},{"location":"components/sdk-mac/#_1","text":"To receive this data on a second device, simply implement the delegate. class ViewController: UIViewController, oxyDelegate { } func oxyId(with oxy_id: String!) { DispatchQueue.main.async { //Do some magic } } Start oxyManager!.listen() You are now ready to start using OxySound in your own application.","title":""},{"location":"components/sdk-wasm/","text":"Getting Started - WebAssembly \u00b6 The OxySound WebAssembly SDK brings our technology to the web, allowing you to send and receive data over sound in the browser, using a simple JavaScript interface. With the WebAssembly SDK you can integrate OxySound into web pages and apps, and the exact same code can be executed on many different devices, both desktop and mobile. The SDK never sends audio data to the cloud, running all of the audio processing locally on your device. Known Issues \u00b6 1). Android and iOS devices do not detect frequencies above 8kHz and 11kHz respectively in the browser. However ultrasonic protocols are an option for desktop only applications. 2). The SDK will not work on iOS Chrome, as getUserMedia is not supported in a WKWebView. See the open radar bug report. Download \u00b6 WASM / Javascript","title":"WebAssembly"},{"location":"components/sdk-wasm/#getting-started-webassembly","text":"The OxySound WebAssembly SDK brings our technology to the web, allowing you to send and receive data over sound in the browser, using a simple JavaScript interface. With the WebAssembly SDK you can integrate OxySound into web pages and apps, and the exact same code can be executed on many different devices, both desktop and mobile. The SDK never sends audio data to the cloud, running all of the audio processing locally on your device.","title":"Getting Started - WebAssembly"},{"location":"components/sdk-wasm/#known-issues","text":"1). Android and iOS devices do not detect frequencies above 8kHz and 11kHz respectively in the browser. However ultrasonic protocols are an option for desktop only applications. 2). The SDK will not work on iOS Chrome, as getUserMedia is not supported in a WKWebView. See the open radar bug report.","title":"Known Issues"},{"location":"components/sdk-wasm/#download","text":"WASM / Javascript","title":"Download"},{"location":"components/unity/","text":"Getting Started - Unity \u00b6 The plugin is a wrapper around the iOS / Android SDK Start \u00b6 OxyManager.StartSDK Stop \u00b6 OxyManager.StopSDK","title":"Unity Plugin"},{"location":"components/unity/#getting-started-unity","text":"The plugin is a wrapper around the iOS / Android SDK","title":"Getting Started - Unity"},{"location":"components/unity/#start","text":"OxyManager.StartSDK","title":"Start"},{"location":"components/unity/#stop","text":"OxyManager.StopSDK","title":"Stop"},{"location":"project/","text":"Sample audio \u00b6 Open application and then click on a media sample Sample pack \u00b6 XCode and Android Studio Source Code git clone https://6a27cc25f771607890406ba50eb3348a857a5959@github.com/OxySound/clients.git Download Pack Click when application is open to hear tones: Mixed with audio file (Near-Ultrasonic) \u00b6 Youtube / Netflix intergration (Compression) \u00b6","title":"Overview"},{"location":"project/#sample-audio","text":"Open application and then click on a media sample","title":"Sample audio"},{"location":"project/#sample-pack","text":"XCode and Android Studio Source Code git clone https://6a27cc25f771607890406ba50eb3348a857a5959@github.com/OxySound/clients.git Download Pack Click when application is open to hear tones:","title":"Sample pack"},{"location":"project/#mixed-with-audio-file-near-ultrasonic","text":"","title":"Mixed with audio file (Near-Ultrasonic)"},{"location":"project/#youtube-netflix-intergration-compression","text":"","title":"Youtube / Netflix intergration (Compression)"},{"location":"tutorials/","text":"Tutorials \u00b6 OxySound SDKs make sending data with audio incredibly straightforward for developers. Data is provided to the SDKs as an array of bytes. This means that any arbitrary data can be sent in its existing form without the SDK requiring any complicated conversions of data types or esoteric schema. Transmission of the data can be via audible or inaudible ultrasonic audio depending on the configuration of your OxySound SDK. And you can get started with both the ultrasound and standard protocols for free in minutes.","title":"Tutorials"},{"location":"tutorials/#tutorials","text":"OxySound SDKs make sending data with audio incredibly straightforward for developers. Data is provided to the SDKs as an array of bytes. This means that any arbitrary data can be sent in its existing form without the SDK requiring any complicated conversions of data types or esoteric schema. Transmission of the data can be via audible or inaudible ultrasonic audio depending on the configuration of your OxySound SDK. And you can get started with both the ultrasound and standard protocols for free in minutes.","title":"Tutorials"},{"location":"tutorials/android-hello/","text":"iPhone App \u00b6 package com.example.oxysound import android.Manifest import android.content.pm.PackageManager import android.graphics.Color import android.os.Bundle import android.util.Log import android.widget.Toast import androidx.appcompat.app.AppCompatActivity import androidx.core.app.ActivityCompat import com.oxy.AndroidOxyCore.OxyCore import com.oxy.AndroidOxyCore.OxyCoreEvent import kotlinx.android.synthetic.main.activity_main.* import java.util.* private lateinit var SDKOxyCore: OxyCore private const val REQUEST_RECORD_AUDIO = 1 private var t = 1 class MainActivity : AppCompatActivity(), OxyCoreEvent { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) //Provide Context for Callback SDKOxyCore = OxyCore(this) } override fun onPause() { super.onPause() //Pause SDK SDKOxyCore.Stop() } override fun onDestroy() { super.onDestroy()c } private fun distance() { SDKOxyCore.distancevol().toString() } //Callback override fun IdWith(Id: String) { when (Id) { \"qa034\" -> { val rnd = Random() val color = Color.argb(255, rnd.nextInt(256), rnd.nextInt(256), rnd.nextInt(256)) mainlayout.setBackgroundColor(color) } else -> { distance() val rnd = Random() Toast.makeText(this@MainActivity, Id, Toast.LENGTH_SHORT).show() val color = Color.argb(255, rnd.nextInt(256), rnd.nextInt(256), rnd.nextInt(256)) mainlayout.setBackgroundColor(color) } } } // Request microphone permissions override fun onResume() { super.onResume() SDKOxyCore.Listen() } }","title":"iPhone App"},{"location":"tutorials/android-hello/#iphone-app","text":"package com.example.oxysound import android.Manifest import android.content.pm.PackageManager import android.graphics.Color import android.os.Bundle import android.util.Log import android.widget.Toast import androidx.appcompat.app.AppCompatActivity import androidx.core.app.ActivityCompat import com.oxy.AndroidOxyCore.OxyCore import com.oxy.AndroidOxyCore.OxyCoreEvent import kotlinx.android.synthetic.main.activity_main.* import java.util.* private lateinit var SDKOxyCore: OxyCore private const val REQUEST_RECORD_AUDIO = 1 private var t = 1 class MainActivity : AppCompatActivity(), OxyCoreEvent { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) //Provide Context for Callback SDKOxyCore = OxyCore(this) } override fun onPause() { super.onPause() //Pause SDK SDKOxyCore.Stop() } override fun onDestroy() { super.onDestroy()c } private fun distance() { SDKOxyCore.distancevol().toString() } //Callback override fun IdWith(Id: String) { when (Id) { \"qa034\" -> { val rnd = Random() val color = Color.argb(255, rnd.nextInt(256), rnd.nextInt(256), rnd.nextInt(256)) mainlayout.setBackgroundColor(color) } else -> { distance() val rnd = Random() Toast.makeText(this@MainActivity, Id, Toast.LENGTH_SHORT).show() val color = Color.argb(255, rnd.nextInt(256), rnd.nextInt(256), rnd.nextInt(256)) mainlayout.setBackgroundColor(color) } } } // Request microphone permissions override fun onResume() { super.onResume() SDKOxyCore.Listen() } }","title":"iPhone App"},{"location":"tutorials/iphone-hello/","text":"iPhone App \u00b6 import Oxy import UIKit import AVFoundation /** - Note: OxySound Framework Example This class contains common delegate, methods and constants that are used in all application controllers The constructor`OxyManager` contains all the controls of the OxySound SDK **Basic Example SDK configuration:** let OxyManager = Oxy.instance() oxyManager?.delegate=self oxyManager!.listen() Note: The method OxyManager.delegate = self() sets the callback for OK decodes The mehtod OxyManager.instance() initialize the SDK. The method OxyManager.listen() starts the SDK into listening mode the default The method OxyManager.stop() starts the SDK into listening mode the default */ class ViewController: UIViewController, oxyDelegate { @IBOutlet weak var wipbtn: UIButton! //Instance let oxyManager = Oxy.instance() let amax:Float = -110 //door //MARK: Flow control of payload var tog:Bool = false var payload:String = \"\" override func viewDidLoad() { super.viewDidLoad() //Assign delegate oxyManager?.delegate=self //Start engine oxyManager!.listen() } //MARK: Still processing audio push to new thread func oxyId(with oxy_id: String!) { if(self.payload != oxy_id){ self.payload = oxy_id self.tog = true } DispatchQueue.main.async { switch self.payload { case \"91876\": self.view.backgroundColor = self.random() if(self.tog == true) { /* Future use self.tog = false */ self.addimage() } case \"88888\": self.toggleTorch(on: true) self.toggleTorch(on: true) self.toggleTorch(on: false) case \"12345\": //self.view.backgroundColor = self.UIColorFromHex(rgbValue: 0xD61E1E,alpha: 1) //self.view.backgroundColor = self.random() //self.showToast(oxy_id) if(self.oxyManager!.distanceVol() < self.amax ) { print(self.oxyManager!.distanceVol()) self.showToast(\"Move device closer\") self.view.backgroundColor = // Red self.UIColorFromHex(rgbValue: 0xD61E1E,alpha: 1) }else{ self.showToast(\"Device within range\") // Green self.view.backgroundColor = self.UIColorFromHex(rgbValue: 0x228B22,alpha: 1) } default: self.view.backgroundColor = self.random() self.showToast(oxy_id) //print(oxy_id as Any) } } } func random() -> UIColor { return UIColor(red: .random(in: 0...1), green: .random(in: 0...1), blue: .random(in: 0...1), alpha: 1.0) } func addimage(){ var number = Int.random(in: 0 ..< 900) var number2 = Int.random(in: 0 ..< 900) //Create image view simply like this. let imgView = UIImageView() imgView.frame = CGRect(x: number, y: number2, width: 200, height: 200) imgView.image = UIImage(named: \"uv\")//Assign image to ImageView imgView.imgViewCorners() view.addSubview(imgView)//Add image to our view } func UIColorFromHex(rgbValue:UInt32, alpha:Double=1.0)->UIColor { let red = CGFloat((rgbValue & 0xFF0000) >> 16)/256.0 let green = CGFloat((rgbValue & 0xFF00) >> 8)/256.0 let blue = CGFloat(rgbValue & 0xFF)/256.0 return UIColor(red:red, green:green, blue:blue, alpha:CGFloat(alpha)) } func toggleTorch(on: Bool) { guard let device = AVCaptureDevice.default(for: AVMediaType.video), device.hasTorch else { return } do { try device.lockForConfiguration() device.torchMode = on ? .on : .off device.unlockForConfiguration() } catch { print(\"Torch could not be used\") } } } extension UIImageView { //If you want only round corners func imgViewCorners() { layer.cornerRadius = 10 layer.borderWidth = 1.0 layer.masksToBounds = true } }","title":"iPhone App"},{"location":"tutorials/iphone-hello/#iphone-app","text":"import Oxy import UIKit import AVFoundation /** - Note: OxySound Framework Example This class contains common delegate, methods and constants that are used in all application controllers The constructor`OxyManager` contains all the controls of the OxySound SDK **Basic Example SDK configuration:** let OxyManager = Oxy.instance() oxyManager?.delegate=self oxyManager!.listen() Note: The method OxyManager.delegate = self() sets the callback for OK decodes The mehtod OxyManager.instance() initialize the SDK. The method OxyManager.listen() starts the SDK into listening mode the default The method OxyManager.stop() starts the SDK into listening mode the default */ class ViewController: UIViewController, oxyDelegate { @IBOutlet weak var wipbtn: UIButton! //Instance let oxyManager = Oxy.instance() let amax:Float = -110 //door //MARK: Flow control of payload var tog:Bool = false var payload:String = \"\" override func viewDidLoad() { super.viewDidLoad() //Assign delegate oxyManager?.delegate=self //Start engine oxyManager!.listen() } //MARK: Still processing audio push to new thread func oxyId(with oxy_id: String!) { if(self.payload != oxy_id){ self.payload = oxy_id self.tog = true } DispatchQueue.main.async { switch self.payload { case \"91876\": self.view.backgroundColor = self.random() if(self.tog == true) { /* Future use self.tog = false */ self.addimage() } case \"88888\": self.toggleTorch(on: true) self.toggleTorch(on: true) self.toggleTorch(on: false) case \"12345\": //self.view.backgroundColor = self.UIColorFromHex(rgbValue: 0xD61E1E,alpha: 1) //self.view.backgroundColor = self.random() //self.showToast(oxy_id) if(self.oxyManager!.distanceVol() < self.amax ) { print(self.oxyManager!.distanceVol()) self.showToast(\"Move device closer\") self.view.backgroundColor = // Red self.UIColorFromHex(rgbValue: 0xD61E1E,alpha: 1) }else{ self.showToast(\"Device within range\") // Green self.view.backgroundColor = self.UIColorFromHex(rgbValue: 0x228B22,alpha: 1) } default: self.view.backgroundColor = self.random() self.showToast(oxy_id) //print(oxy_id as Any) } } } func random() -> UIColor { return UIColor(red: .random(in: 0...1), green: .random(in: 0...1), blue: .random(in: 0...1), alpha: 1.0) } func addimage(){ var number = Int.random(in: 0 ..< 900) var number2 = Int.random(in: 0 ..< 900) //Create image view simply like this. let imgView = UIImageView() imgView.frame = CGRect(x: number, y: number2, width: 200, height: 200) imgView.image = UIImage(named: \"uv\")//Assign image to ImageView imgView.imgViewCorners() view.addSubview(imgView)//Add image to our view } func UIColorFromHex(rgbValue:UInt32, alpha:Double=1.0)->UIColor { let red = CGFloat((rgbValue & 0xFF0000) >> 16)/256.0 let green = CGFloat((rgbValue & 0xFF00) >> 8)/256.0 let blue = CGFloat(rgbValue & 0xFF)/256.0 return UIColor(red:red, green:green, blue:blue, alpha:CGFloat(alpha)) } func toggleTorch(on: Bool) { guard let device = AVCaptureDevice.default(for: AVMediaType.video), device.hasTorch else { return } do { try device.lockForConfiguration() device.torchMode = on ? .on : .off device.unlockForConfiguration() } catch { print(\"Torch could not be used\") } } } extension UIImageView { //If you want only round corners func imgViewCorners() { layer.cornerRadius = 10 layer.borderWidth = 1.0 layer.masksToBounds = true } }","title":"iPhone App"}]}